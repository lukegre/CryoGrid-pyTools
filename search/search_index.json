{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CryoGrid-pyTools CryoGrid-pyTools is a Python package designed to facilitate working with CryoGrid MATLAB data in Python. It provides tools for reading and processing various types of data including: CryoGrid output (from OUT_regridded_FCI2 ) Simple MATLAB struct files ERA5 forcing data Excel run configuration files Features Easy-to-use interface for reading CryoGrid output files Support for both single and multiple file reading Conversion of MATLAB data structures to Python Integration with common data science libraries like xarray Quick Links Installation Guide Getting Started API Reference License This project is licensed under the MIT License - see the LICENSE file for details.","title":"Home"},{"location":"#cryogrid-pytools","text":"CryoGrid-pyTools is a Python package designed to facilitate working with CryoGrid MATLAB data in Python. It provides tools for reading and processing various types of data including: CryoGrid output (from OUT_regridded_FCI2 ) Simple MATLAB struct files ERA5 forcing data Excel run configuration files","title":"CryoGrid-pyTools"},{"location":"#features","text":"Easy-to-use interface for reading CryoGrid output files Support for both single and multiple file reading Conversion of MATLAB data structures to Python Integration with common data science libraries like xarray","title":"Features"},{"location":"#quick-links","text":"Installation Guide Getting Started API Reference","title":"Quick Links"},{"location":"#license","text":"This project is licensed under the MIT License - see the LICENSE file for details.","title":"License"},{"location":"api-reference/","text":"API Reference This page contains the detailed API reference for CryoGrid-pyTools. Main Functions cryogrid_pytools.read_OUT_regridded_FCI2_file(fname, deepest_point=None) Read a CryoGrid OUT_regridded_FCI2 file and return it as an xarray dataset. Parameters fname : str Path to the .mat file deepest_point : float, optional Represents the deepest depth of the profile. If not provided, then elevation is returned. Negative values represent depths below the surface. Returns ds : xarray.Dataset Dataset with dimensions 'time' and 'level'. The CryoGrid variable depths is renamed to elevation . If deepest_point is provided, then depth will represent the depth below the surface (negative below surface). Source code in cryogrid_pytools/outputs.py def read_OUT_regridded_FCI2_file(fname:str, deepest_point=None)->xr.Dataset: \"\"\" Read a CryoGrid OUT_regridded_FCI2 file and return it as an xarray dataset. Parameters ---------- fname : str Path to the .mat file deepest_point : float, optional Represents the deepest depth of the profile. If not provided, then elevation is returned. Negative values represent depths below the surface. Returns ------- ds : xarray.Dataset Dataset with dimensions 'time' and 'level'. The CryoGrid variable `depths` is renamed to `elevation`. If deepest_point is provided, then `depth` will represent the depth below the surface (negative below surface). \"\"\" from .matlab_helpers import read_mat_struct_flat_as_dict, matlab2datetime dat = read_mat_struct_flat_as_dict(fname) for key in dat: dat[key] = dat[key].squeeze() ds = xr.Dataset() ds.attrs['filename'] = fname times = matlab2datetime(dat.pop('timestamp')) elevation = dat.pop('depths') for key in dat: ds[key] = xr.DataArray( data = dat[key].astype('float32'), dims=['level', 'time'], coords={'time': times}) ds['elevation'] = xr.DataArray(elevation, dims=['level']) if deepest_point is not None: assert deepest_point < 0, \"deepest_point must be negative (below surface)\" ds = ds.rename(level='depth') # calculate depth step size n = elevation.size - 1 s = (elevation[-1] - elevation[0]) / n significant_number = np.abs(np.floor(np.log10((np.abs(s))))).astype(int) # calculate shallowest point based on step size and n shallowest_point = deepest_point - (s * n) deepest_point += s / 2 # adding half step for arange depth = np.arange(shallowest_point, deepest_point, s, dtype='float32').round(significant_number) ds['depth'] = xr.DataArray(depth, dims=['depth']) ds = ds.set_coords('depth') ds = ds.transpose('depth', 'time', ...) else: ds = ds.transpose('elevation', 'time', ...) ds = ds.chunk(dict(time=-1)) return ds cryogrid_pytools.read_OUT_regridded_FCI2_clusters(fname_glob, deepest_point, **joblib_kwargs) Reads multiple files that are put out by the OUT_regridded_FCI2 class Parameters fname_glob: str Path of the files that you want to read in. Use same notation as for glob(). Note that it expects name to follow the format some_project_name_GRIDCELL_date.mat where GRIDCELL will be extracted to assign the gridcell dimension. These GRIDCELLs correspond with the index of the data in the flattened array. deepest_point: float When setting the configuration for when the data should be saved, the maximum depth is set. Give this number as a negative number here. joblib_kwargs: dict Uses the joblib library to do parallel reading of the files. Defaults are: n_jobs=-1, backend='threading', verbose=1 Returns xr.Dataset An array with dimensions gridcell, depth, time. Variables depend on how the class was configured, but elevation will also be a variable. Source code in cryogrid_pytools/outputs.py def read_OUT_regridded_FCI2_clusters(fname_glob:str, deepest_point:float, **joblib_kwargs)->xr.Dataset: \"\"\" Reads multiple files that are put out by the OUT_regridded_FCI2 class Parameters ---------- fname_glob: str Path of the files that you want to read in. Use same notation as for glob(). Note that it expects name to follow the format `some_project_name_GRIDCELL_date.mat` where GRIDCELL will be extracted to assign the gridcell dimension. These GRIDCELLs correspond with the index of the data in the flattened array. deepest_point: float When setting the configuration for when the data should be saved, the maximum depth is set. Give this number as a negative number here. joblib_kwargs: dict Uses the joblib library to do parallel reading of the files. Defaults are: n_jobs=-1, backend='threading', verbose=1 Returns ------- xr.Dataset An array with dimensions gridcell, depth, time. Variables depend on how the class was configured, but elevation will also be a variable. \"\"\" from glob import glob # get the file list flist = sorted(glob(fname_glob)) # extract the gridcell from the file name gridcell = [int(f.split('_')[-2]) for f in flist] list_of_ds = _read_OUT_regridded_FCI2_parallel(fname_glob, deepest_point, **joblib_kwargs) # assign the gridcell dimension so that we can combine the data by coordinates and time list_of_ds = [ds.assign_coords(gridcell=[c]) for ds, c in zip(list_of_ds, gridcell)] ds = xr.combine_by_coords(list_of_ds, combine_attrs='drop_conflicts') # transpose data so that plotting is quick and easy ds = ds.transpose('gridcell', 'depth', 'time', ...) return ds cryogrid_pytools.matlab_helpers.read_mat_struct_flat_as_dict(fname, key=None) Read a MATLAB struct from a .mat file and return it as a dictionary. Assumes that the struct is flat, i.e. it does not contain any nested structs. Parameters fname : str Path to the .mat file key : str, optional The name of the matlab key in the .mat file. If None is passed [default], then the first key that does not start with an underscore is used. If a string is passed, then the corresponding key is used. Returns data : dict Dictionary with the struct fields as keys and the corresponding data as values. Source code in cryogrid_pytools/matlab_helpers.py def read_mat_struct_flat_as_dict(fname: str, key=None) -> dict: \"\"\" Read a MATLAB struct from a .mat file and return it as a dictionary. Assumes that the struct is flat, i.e. it does not contain any nested structs. Parameters ---------- fname : str Path to the .mat file key : str, optional The name of the matlab key in the .mat file. If None is passed [default], then the first key that does not start with an underscore is used. If a string is passed, then the corresponding key is used. Returns ------- data : dict Dictionary with the struct fields as keys and the corresponding data as values. \"\"\" from scipy.io import loadmat raw = loadmat(fname) keys = [k for k in raw.keys() if not k.startswith('_')] if key is None: logger.log(5, f\"No key specified. Using first key that does not start with an underscore: {keys[0]}\") key = keys[0] elif key not in keys: raise ValueError(f\"Key '{key}' not found in .mat file. Available keys are: {keys}\") named_array = unnest_matlab_struct_named_array(raw[key]) data = {k: named_array[k].squeeze() for k in named_array.dtype.names} return data Data Module Functions cryogrid_pytools.data.get_dem_copernicus30(bbox_WSEN, res_m=30, epsg=32643, smoothing_iters=2, smoothing_size=3) Download DEM data from the STAC catalog (default is COP DEM Global 30m). Parameters bbox_WSEN : list The bounding box of the area of interest in WSEN format. res_m : int The resolution of the DEM data in meters. epsg : int, optional The EPSG code of the projection of the DEM data. Default is EPSG:32643 (UTM 43N) for the Pamir region. smoothing_iters : int, optional The number of iterations to apply the smoothing filter. Default is 2. Set to 0 to disable smoothing. smoothing_size : int, optional The size of the kernel (num pixels) for the smoothing filter. Default is 3. Returns xarray.DataArray The DEM data as an xarray DataArray with attributes. Source code in cryogrid_pytools/data.py @_decorator_dataarray_to_bbox def get_dem_copernicus30(bbox_WSEN:list, res_m:int=30, epsg=32643, smoothing_iters=2, smoothing_size=3)->_xr.DataArray: \"\"\" Download DEM data from the STAC catalog (default is COP DEM Global 30m). Parameters ---------- bbox_WSEN : list The bounding box of the area of interest in WSEN format. res_m : int The resolution of the DEM data in meters. epsg : int, optional The EPSG code of the projection of the DEM data. Default is EPSG:32643 (UTM 43N) for the Pamir region. smoothing_iters : int, optional The number of iterations to apply the smoothing filter. Default is 2. Set to 0 to disable smoothing. smoothing_size : int, optional The size of the kernel (num pixels) for the smoothing filter. Default is 3. Returns ------- xarray.DataArray The DEM data as an xarray DataArray with attributes. \"\"\" check_epsg(epsg) assert res_m >= 30, \"The resolution must be greater than 30m for the COP DEM Global 30m dataset.\" res = res_m / 111111 if epsg == 4326 else res_m _logger.info(\"Fetching COP DEM Global 30m data from Planetary Computer\") items = search_stac_items_planetary_computer('cop-dem-glo-30', bbox_WSEN) da_dem = _stackstac.stack( items=items, bounds_latlon=bbox_WSEN, resolution=res, epsg=epsg) da_dem = ( da_dem .mean('time') .squeeze() .pipe(drop_coords_without_dim) .pipe(smooth_data, n_iters=smoothing_iters, kernel_size=smoothing_size) .rio.write_crs(f\"EPSG:{epsg}\") .assign_attrs( source=items[0].links[0].href, # collection URL bbox_request=bbox_WSEN)) return da_dem cryogrid_pytools.data.get_esa_land_cover(bbox_WSEN, res_m=30, epsg=32643) Get the ESA World Cover dataset on the target grid and resolution. Parameters bbox_WSEN : tuple Bounding box in the format (West, South, East, North). res_m : int, optional Resolution in meters. Defaults to 30. epsg : int, optional EPSG code for the coordinate reference system. Defaults to 32643. Returns xr.DataArray A DataArray with the land cover data on the target grid. Contains attributes 'class_values', 'class_descriptions', 'class_colors' for plotting. Source code in cryogrid_pytools/data.py @_decorator_dataarray_to_bbox def get_esa_land_cover(bbox_WSEN:tuple, res_m:int=30, epsg=32643)->_xr.DataArray: \"\"\" Get the ESA World Cover dataset on the target grid and resolution. Parameters ---------- bbox_WSEN : tuple Bounding box in the format (West, South, East, North). res_m : int, optional Resolution in meters. Defaults to 30. epsg : int, optional EPSG code for the coordinate reference system. Defaults to 32643. Returns ------- xr.DataArray A DataArray with the land cover data on the target grid. Contains attributes 'class_values', 'class_descriptions', 'class_colors' for plotting. \"\"\" def get_land_cover_classes(item): \"\"\" Get the land cover class names, and colors from the ESA World Cover dataset Args: item (pystac.Item): The STAC item containing the land cover data. Returns: dict: A dictionary with class values, descriptions, and colors. \"\"\" import pandas as pd classes = item.assets['map'].extra_fields['classification:classes'] df = pd.DataFrame(classes).set_index('value') df['color-hint'] = '#' + df['color-hint'] out = dict( class_values = df.index.values, class_descriptions = df['description'].values, class_colors = df['color-hint'].values) return out # make sure epsg is supported check_epsg(epsg) # get the units in the projection res = get_res_in_proj_units(res_m, epsg, min_res=10) _logger.info(\"Fetching ESA World Cover (v2.0) data from Planetary Computer\") items = search_stac_items_planetary_computer( collection='esa-worldcover', bbox=bbox_WSEN, query={'esa_worldcover:product_version': {'eq': '2.0.0'}}) stac_props = dict( items=items, assets=['map'], epsg=epsg, bounds_latlon=bbox_WSEN, resolution=res) da = ( _stackstac.stack(**stac_props) .max(['band', 'time'], keep_attrs=True) # removing the single band dimension .rename('land_cover') .assign_attrs(**get_land_cover_classes(items[0])) ) return da cryogrid_pytools.data.get_snow_melt_doy(bbox_WSEN, years=range(2018, 2025), res_m=30, epsg=32643) Calculate the snow melt day of year (DOY) from Sentinel-2 SCL data for a given bounding box and years. Parameters bbox_WSEN : tuple Bounding box coordinates in the format (West, South, East, North). years : range, optional Range of years to consider. Defaults to range(2018, 2025). res_m : int, optional Spatial resolution in meters. Defaults to 30. epsg : int, optional EPSG code for the coordinate reference system. Defaults to 32643. Returns _xr.DataArray DataArray containing the snow melt DOY for each year. Source code in cryogrid_pytools/data.py @_decorator_dataarray_to_bbox def get_snow_melt_doy(bbox_WSEN:tuple, years=range(2018, 2025), res_m:int=30, epsg=32643)->_xr.DataArray: \"\"\" Calculate the snow melt day of year (DOY) from Sentinel-2 SCL data for a given bounding box and years. Parameters ---------- bbox_WSEN : tuple Bounding box coordinates in the format (West, South, East, North). years : range, optional Range of years to consider. Defaults to range(2018, 2025). res_m : int, optional Spatial resolution in meters. Defaults to 30. epsg : int, optional EPSG code for the coordinate reference system. Defaults to 32643. Returns ------- _xr.DataArray DataArray containing the snow melt DOY for each year. \"\"\" da = get_sentinel2_data(bbox_WSEN, years=years, res_m=res_m, epsg=epsg, max_cloud_cover=10) _logger.info(\"Calculating snow melt day of year (DOY) from Sentinel-2 SCL data\") doy = da.groupby('time.year').apply(calc_sentinel2_snow_melt_doy) return doy cryogrid_pytools.data.get_randolph_glacier_inventory(target_dem=None, dest_dir=None) Fetches the Randolph Glacier Inventory (RGI) data and returns it as a GeoDataFrame or raster dataset. Parameters target_dem : optional A digital elevation model (DEM) object. If provided, the function will return the RGI data clipped to the bounding box of the DEM and reprojected to the DEM's CRS. dest_dir : str, optional The directory where the downloaded RGI data will be stored. If None, the data will be stored in the pooch cache directory (~/.cache/pooch/). Returns GeoDataFrame or raster dataset If target_dem is None, returns a GeoDataFrame containing the RGI data. If target_dem is provided, returns a raster dataset clipped and reprojected to the DEM. Source code in cryogrid_pytools/data.py @_cached def get_randolph_glacier_inventory(target_dem=None, dest_dir=None): \"\"\" Fetches the Randolph Glacier Inventory (RGI) data and returns it as a GeoDataFrame or raster dataset. Parameters ---------- target_dem : optional A digital elevation model (DEM) object. If provided, the function will return the RGI data clipped to the bounding box of the DEM and reprojected to the DEM's CRS. dest_dir : str, optional The directory where the downloaded RGI data will be stored. If None, the data will be stored in the pooch cache directory (~/.cache/pooch/). Returns ------- GeoDataFrame or raster dataset If target_dem is None, returns a GeoDataFrame containing the RGI data. If target_dem is provided, returns a raster dataset clipped and reprojected to the DEM. \"\"\" url = 'https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0770_rgi_v7/regional_files/RGI2000-v7.0-G/RGI2000-v7.0-G-13_central_asia.zip' downloader = _pooch.HTTPDownloader(progressbar=True, headers=get_earthaccess_session().headers) flist = download_url(url, path=dest_dir, downloader=downloader) fname_shp = [f for f in flist if f.endswith('.shp')][0] _logger.log(\"INFO\", f\"RGI: Fetching Randolph Glacier Inventory - see https://www.glims.org/rgi_user_guide/welcome.html\") _logger.log(\"DEBUG\", f\"RGI: URL = {url}\") _logger.log(\"DEBUG\", f\"RGI: FILE = {fname_shp}\") if target_dem is None: # reads the whole file df = _gpd.read_file(fname_shp) else: # gets the bounding box and then reads the file bbox = target_dem.rv.get_bbox_latlon() df = _gpd.read_file(fname_shp, bbox=bbox).to_crs(target_dem.rio.crs) df = df.dissolve() ds = df.rv.to_raster(target_dem) return ds return df Utility Functions Additional utility functions are available in the package. See the source code documentation for more details.","title":"API Reference"},{"location":"api-reference/#api-reference","text":"This page contains the detailed API reference for CryoGrid-pyTools.","title":"API Reference"},{"location":"api-reference/#main-functions","text":"","title":"Main Functions"},{"location":"api-reference/#cryogrid_pytools.read_OUT_regridded_FCI2_file","text":"Read a CryoGrid OUT_regridded_FCI2 file and return it as an xarray dataset.","title":"read_OUT_regridded_FCI2_file"},{"location":"api-reference/#cryogrid_pytools.read_OUT_regridded_FCI2_file--parameters","text":"fname : str Path to the .mat file deepest_point : float, optional Represents the deepest depth of the profile. If not provided, then elevation is returned. Negative values represent depths below the surface.","title":"Parameters"},{"location":"api-reference/#cryogrid_pytools.read_OUT_regridded_FCI2_file--returns","text":"ds : xarray.Dataset Dataset with dimensions 'time' and 'level'. The CryoGrid variable depths is renamed to elevation . If deepest_point is provided, then depth will represent the depth below the surface (negative below surface). Source code in cryogrid_pytools/outputs.py def read_OUT_regridded_FCI2_file(fname:str, deepest_point=None)->xr.Dataset: \"\"\" Read a CryoGrid OUT_regridded_FCI2 file and return it as an xarray dataset. Parameters ---------- fname : str Path to the .mat file deepest_point : float, optional Represents the deepest depth of the profile. If not provided, then elevation is returned. Negative values represent depths below the surface. Returns ------- ds : xarray.Dataset Dataset with dimensions 'time' and 'level'. The CryoGrid variable `depths` is renamed to `elevation`. If deepest_point is provided, then `depth` will represent the depth below the surface (negative below surface). \"\"\" from .matlab_helpers import read_mat_struct_flat_as_dict, matlab2datetime dat = read_mat_struct_flat_as_dict(fname) for key in dat: dat[key] = dat[key].squeeze() ds = xr.Dataset() ds.attrs['filename'] = fname times = matlab2datetime(dat.pop('timestamp')) elevation = dat.pop('depths') for key in dat: ds[key] = xr.DataArray( data = dat[key].astype('float32'), dims=['level', 'time'], coords={'time': times}) ds['elevation'] = xr.DataArray(elevation, dims=['level']) if deepest_point is not None: assert deepest_point < 0, \"deepest_point must be negative (below surface)\" ds = ds.rename(level='depth') # calculate depth step size n = elevation.size - 1 s = (elevation[-1] - elevation[0]) / n significant_number = np.abs(np.floor(np.log10((np.abs(s))))).astype(int) # calculate shallowest point based on step size and n shallowest_point = deepest_point - (s * n) deepest_point += s / 2 # adding half step for arange depth = np.arange(shallowest_point, deepest_point, s, dtype='float32').round(significant_number) ds['depth'] = xr.DataArray(depth, dims=['depth']) ds = ds.set_coords('depth') ds = ds.transpose('depth', 'time', ...) else: ds = ds.transpose('elevation', 'time', ...) ds = ds.chunk(dict(time=-1)) return ds","title":"Returns"},{"location":"api-reference/#cryogrid_pytools.read_OUT_regridded_FCI2_clusters","text":"Reads multiple files that are put out by the OUT_regridded_FCI2 class","title":"read_OUT_regridded_FCI2_clusters"},{"location":"api-reference/#cryogrid_pytools.read_OUT_regridded_FCI2_clusters--parameters","text":"fname_glob: str Path of the files that you want to read in. Use same notation as for glob(). Note that it expects name to follow the format some_project_name_GRIDCELL_date.mat where GRIDCELL will be extracted to assign the gridcell dimension. These GRIDCELLs correspond with the index of the data in the flattened array. deepest_point: float When setting the configuration for when the data should be saved, the maximum depth is set. Give this number as a negative number here. joblib_kwargs: dict Uses the joblib library to do parallel reading of the files. Defaults are: n_jobs=-1, backend='threading', verbose=1","title":"Parameters"},{"location":"api-reference/#cryogrid_pytools.read_OUT_regridded_FCI2_clusters--returns","text":"xr.Dataset An array with dimensions gridcell, depth, time. Variables depend on how the class was configured, but elevation will also be a variable. Source code in cryogrid_pytools/outputs.py def read_OUT_regridded_FCI2_clusters(fname_glob:str, deepest_point:float, **joblib_kwargs)->xr.Dataset: \"\"\" Reads multiple files that are put out by the OUT_regridded_FCI2 class Parameters ---------- fname_glob: str Path of the files that you want to read in. Use same notation as for glob(). Note that it expects name to follow the format `some_project_name_GRIDCELL_date.mat` where GRIDCELL will be extracted to assign the gridcell dimension. These GRIDCELLs correspond with the index of the data in the flattened array. deepest_point: float When setting the configuration for when the data should be saved, the maximum depth is set. Give this number as a negative number here. joblib_kwargs: dict Uses the joblib library to do parallel reading of the files. Defaults are: n_jobs=-1, backend='threading', verbose=1 Returns ------- xr.Dataset An array with dimensions gridcell, depth, time. Variables depend on how the class was configured, but elevation will also be a variable. \"\"\" from glob import glob # get the file list flist = sorted(glob(fname_glob)) # extract the gridcell from the file name gridcell = [int(f.split('_')[-2]) for f in flist] list_of_ds = _read_OUT_regridded_FCI2_parallel(fname_glob, deepest_point, **joblib_kwargs) # assign the gridcell dimension so that we can combine the data by coordinates and time list_of_ds = [ds.assign_coords(gridcell=[c]) for ds, c in zip(list_of_ds, gridcell)] ds = xr.combine_by_coords(list_of_ds, combine_attrs='drop_conflicts') # transpose data so that plotting is quick and easy ds = ds.transpose('gridcell', 'depth', 'time', ...) return ds","title":"Returns"},{"location":"api-reference/#cryogrid_pytools.matlab_helpers.read_mat_struct_flat_as_dict","text":"Read a MATLAB struct from a .mat file and return it as a dictionary. Assumes that the struct is flat, i.e. it does not contain any nested structs.","title":"read_mat_struct_flat_as_dict"},{"location":"api-reference/#cryogrid_pytools.matlab_helpers.read_mat_struct_flat_as_dict--parameters","text":"fname : str Path to the .mat file key : str, optional The name of the matlab key in the .mat file. If None is passed [default], then the first key that does not start with an underscore is used. If a string is passed, then the corresponding key is used.","title":"Parameters"},{"location":"api-reference/#cryogrid_pytools.matlab_helpers.read_mat_struct_flat_as_dict--returns","text":"data : dict Dictionary with the struct fields as keys and the corresponding data as values. Source code in cryogrid_pytools/matlab_helpers.py def read_mat_struct_flat_as_dict(fname: str, key=None) -> dict: \"\"\" Read a MATLAB struct from a .mat file and return it as a dictionary. Assumes that the struct is flat, i.e. it does not contain any nested structs. Parameters ---------- fname : str Path to the .mat file key : str, optional The name of the matlab key in the .mat file. If None is passed [default], then the first key that does not start with an underscore is used. If a string is passed, then the corresponding key is used. Returns ------- data : dict Dictionary with the struct fields as keys and the corresponding data as values. \"\"\" from scipy.io import loadmat raw = loadmat(fname) keys = [k for k in raw.keys() if not k.startswith('_')] if key is None: logger.log(5, f\"No key specified. Using first key that does not start with an underscore: {keys[0]}\") key = keys[0] elif key not in keys: raise ValueError(f\"Key '{key}' not found in .mat file. Available keys are: {keys}\") named_array = unnest_matlab_struct_named_array(raw[key]) data = {k: named_array[k].squeeze() for k in named_array.dtype.names} return data","title":"Returns"},{"location":"api-reference/#data-module-functions","text":"","title":"Data Module Functions"},{"location":"api-reference/#cryogrid_pytools.data.get_dem_copernicus30","text":"Download DEM data from the STAC catalog (default is COP DEM Global 30m).","title":"get_dem_copernicus30"},{"location":"api-reference/#cryogrid_pytools.data.get_dem_copernicus30--parameters","text":"bbox_WSEN : list The bounding box of the area of interest in WSEN format. res_m : int The resolution of the DEM data in meters. epsg : int, optional The EPSG code of the projection of the DEM data. Default is EPSG:32643 (UTM 43N) for the Pamir region. smoothing_iters : int, optional The number of iterations to apply the smoothing filter. Default is 2. Set to 0 to disable smoothing. smoothing_size : int, optional The size of the kernel (num pixels) for the smoothing filter. Default is 3.","title":"Parameters"},{"location":"api-reference/#cryogrid_pytools.data.get_dem_copernicus30--returns","text":"xarray.DataArray The DEM data as an xarray DataArray with attributes. Source code in cryogrid_pytools/data.py @_decorator_dataarray_to_bbox def get_dem_copernicus30(bbox_WSEN:list, res_m:int=30, epsg=32643, smoothing_iters=2, smoothing_size=3)->_xr.DataArray: \"\"\" Download DEM data from the STAC catalog (default is COP DEM Global 30m). Parameters ---------- bbox_WSEN : list The bounding box of the area of interest in WSEN format. res_m : int The resolution of the DEM data in meters. epsg : int, optional The EPSG code of the projection of the DEM data. Default is EPSG:32643 (UTM 43N) for the Pamir region. smoothing_iters : int, optional The number of iterations to apply the smoothing filter. Default is 2. Set to 0 to disable smoothing. smoothing_size : int, optional The size of the kernel (num pixels) for the smoothing filter. Default is 3. Returns ------- xarray.DataArray The DEM data as an xarray DataArray with attributes. \"\"\" check_epsg(epsg) assert res_m >= 30, \"The resolution must be greater than 30m for the COP DEM Global 30m dataset.\" res = res_m / 111111 if epsg == 4326 else res_m _logger.info(\"Fetching COP DEM Global 30m data from Planetary Computer\") items = search_stac_items_planetary_computer('cop-dem-glo-30', bbox_WSEN) da_dem = _stackstac.stack( items=items, bounds_latlon=bbox_WSEN, resolution=res, epsg=epsg) da_dem = ( da_dem .mean('time') .squeeze() .pipe(drop_coords_without_dim) .pipe(smooth_data, n_iters=smoothing_iters, kernel_size=smoothing_size) .rio.write_crs(f\"EPSG:{epsg}\") .assign_attrs( source=items[0].links[0].href, # collection URL bbox_request=bbox_WSEN)) return da_dem","title":"Returns"},{"location":"api-reference/#cryogrid_pytools.data.get_esa_land_cover","text":"Get the ESA World Cover dataset on the target grid and resolution.","title":"get_esa_land_cover"},{"location":"api-reference/#cryogrid_pytools.data.get_esa_land_cover--parameters","text":"bbox_WSEN : tuple Bounding box in the format (West, South, East, North). res_m : int, optional Resolution in meters. Defaults to 30. epsg : int, optional EPSG code for the coordinate reference system. Defaults to 32643.","title":"Parameters"},{"location":"api-reference/#cryogrid_pytools.data.get_esa_land_cover--returns","text":"xr.DataArray A DataArray with the land cover data on the target grid. Contains attributes 'class_values', 'class_descriptions', 'class_colors' for plotting. Source code in cryogrid_pytools/data.py @_decorator_dataarray_to_bbox def get_esa_land_cover(bbox_WSEN:tuple, res_m:int=30, epsg=32643)->_xr.DataArray: \"\"\" Get the ESA World Cover dataset on the target grid and resolution. Parameters ---------- bbox_WSEN : tuple Bounding box in the format (West, South, East, North). res_m : int, optional Resolution in meters. Defaults to 30. epsg : int, optional EPSG code for the coordinate reference system. Defaults to 32643. Returns ------- xr.DataArray A DataArray with the land cover data on the target grid. Contains attributes 'class_values', 'class_descriptions', 'class_colors' for plotting. \"\"\" def get_land_cover_classes(item): \"\"\" Get the land cover class names, and colors from the ESA World Cover dataset Args: item (pystac.Item): The STAC item containing the land cover data. Returns: dict: A dictionary with class values, descriptions, and colors. \"\"\" import pandas as pd classes = item.assets['map'].extra_fields['classification:classes'] df = pd.DataFrame(classes).set_index('value') df['color-hint'] = '#' + df['color-hint'] out = dict( class_values = df.index.values, class_descriptions = df['description'].values, class_colors = df['color-hint'].values) return out # make sure epsg is supported check_epsg(epsg) # get the units in the projection res = get_res_in_proj_units(res_m, epsg, min_res=10) _logger.info(\"Fetching ESA World Cover (v2.0) data from Planetary Computer\") items = search_stac_items_planetary_computer( collection='esa-worldcover', bbox=bbox_WSEN, query={'esa_worldcover:product_version': {'eq': '2.0.0'}}) stac_props = dict( items=items, assets=['map'], epsg=epsg, bounds_latlon=bbox_WSEN, resolution=res) da = ( _stackstac.stack(**stac_props) .max(['band', 'time'], keep_attrs=True) # removing the single band dimension .rename('land_cover') .assign_attrs(**get_land_cover_classes(items[0])) ) return da","title":"Returns"},{"location":"api-reference/#cryogrid_pytools.data.get_snow_melt_doy","text":"Calculate the snow melt day of year (DOY) from Sentinel-2 SCL data for a given bounding box and years.","title":"get_snow_melt_doy"},{"location":"api-reference/#cryogrid_pytools.data.get_snow_melt_doy--parameters","text":"bbox_WSEN : tuple Bounding box coordinates in the format (West, South, East, North). years : range, optional Range of years to consider. Defaults to range(2018, 2025). res_m : int, optional Spatial resolution in meters. Defaults to 30. epsg : int, optional EPSG code for the coordinate reference system. Defaults to 32643.","title":"Parameters"},{"location":"api-reference/#cryogrid_pytools.data.get_snow_melt_doy--returns","text":"_xr.DataArray DataArray containing the snow melt DOY for each year. Source code in cryogrid_pytools/data.py @_decorator_dataarray_to_bbox def get_snow_melt_doy(bbox_WSEN:tuple, years=range(2018, 2025), res_m:int=30, epsg=32643)->_xr.DataArray: \"\"\" Calculate the snow melt day of year (DOY) from Sentinel-2 SCL data for a given bounding box and years. Parameters ---------- bbox_WSEN : tuple Bounding box coordinates in the format (West, South, East, North). years : range, optional Range of years to consider. Defaults to range(2018, 2025). res_m : int, optional Spatial resolution in meters. Defaults to 30. epsg : int, optional EPSG code for the coordinate reference system. Defaults to 32643. Returns ------- _xr.DataArray DataArray containing the snow melt DOY for each year. \"\"\" da = get_sentinel2_data(bbox_WSEN, years=years, res_m=res_m, epsg=epsg, max_cloud_cover=10) _logger.info(\"Calculating snow melt day of year (DOY) from Sentinel-2 SCL data\") doy = da.groupby('time.year').apply(calc_sentinel2_snow_melt_doy) return doy","title":"Returns"},{"location":"api-reference/#cryogrid_pytools.data.get_randolph_glacier_inventory","text":"Fetches the Randolph Glacier Inventory (RGI) data and returns it as a GeoDataFrame or raster dataset.","title":"get_randolph_glacier_inventory"},{"location":"api-reference/#cryogrid_pytools.data.get_randolph_glacier_inventory--parameters","text":"target_dem : optional A digital elevation model (DEM) object. If provided, the function will return the RGI data clipped to the bounding box of the DEM and reprojected to the DEM's CRS. dest_dir : str, optional The directory where the downloaded RGI data will be stored. If None, the data will be stored in the pooch cache directory (~/.cache/pooch/).","title":"Parameters"},{"location":"api-reference/#cryogrid_pytools.data.get_randolph_glacier_inventory--returns","text":"GeoDataFrame or raster dataset If target_dem is None, returns a GeoDataFrame containing the RGI data. If target_dem is provided, returns a raster dataset clipped and reprojected to the DEM. Source code in cryogrid_pytools/data.py @_cached def get_randolph_glacier_inventory(target_dem=None, dest_dir=None): \"\"\" Fetches the Randolph Glacier Inventory (RGI) data and returns it as a GeoDataFrame or raster dataset. Parameters ---------- target_dem : optional A digital elevation model (DEM) object. If provided, the function will return the RGI data clipped to the bounding box of the DEM and reprojected to the DEM's CRS. dest_dir : str, optional The directory where the downloaded RGI data will be stored. If None, the data will be stored in the pooch cache directory (~/.cache/pooch/). Returns ------- GeoDataFrame or raster dataset If target_dem is None, returns a GeoDataFrame containing the RGI data. If target_dem is provided, returns a raster dataset clipped and reprojected to the DEM. \"\"\" url = 'https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0770_rgi_v7/regional_files/RGI2000-v7.0-G/RGI2000-v7.0-G-13_central_asia.zip' downloader = _pooch.HTTPDownloader(progressbar=True, headers=get_earthaccess_session().headers) flist = download_url(url, path=dest_dir, downloader=downloader) fname_shp = [f for f in flist if f.endswith('.shp')][0] _logger.log(\"INFO\", f\"RGI: Fetching Randolph Glacier Inventory - see https://www.glims.org/rgi_user_guide/welcome.html\") _logger.log(\"DEBUG\", f\"RGI: URL = {url}\") _logger.log(\"DEBUG\", f\"RGI: FILE = {fname_shp}\") if target_dem is None: # reads the whole file df = _gpd.read_file(fname_shp) else: # gets the bounding box and then reads the file bbox = target_dem.rv.get_bbox_latlon() df = _gpd.read_file(fname_shp, bbox=bbox).to_crs(target_dem.rio.crs) df = df.dissolve() ds = df.rv.to_raster(target_dem) return ds return df","title":"Returns"},{"location":"api-reference/#utility-functions","text":"Additional utility functions are available in the package. See the source code documentation for more details.","title":"Utility Functions"},{"location":"installation/","text":"Installation CryoGrid-pyTools can be easily installed using pip: pip install cryogrid_pytools Optional Dependencies CryoGrid-pyTools has several optional dependency groups that can be installed based on your needs: Documentation Dependencies To build the documentation locally, install with the docs extra: pip install \"cryogrid_pytools[docs]\" Data Processing Dependencies For additional data processing capabilities, install with the data extra: pip install \"cryogrid_pytools[data]\" Development Installation If you want to contribute to the development of CryoGrid-pyTools, you can install from source: git clone https://github.com/lukegre/CryoGrid-pyTools.git cd CryoGrid-pyTools pip install -e \".[docs,data]\" # install with all optional dependencies Requirements CryoGrid-pyTools requires Python 3.9 or later. The main dependencies are: numpy >= 2.0 scipy >= 1.13.1 xarray >= 2024 pandas >= 2 dask[array,diagnostics] >= 2024 These dependencies will be automatically installed when you install the package using pip.","title":"Installation"},{"location":"installation/#installation","text":"CryoGrid-pyTools can be easily installed using pip: pip install cryogrid_pytools","title":"Installation"},{"location":"installation/#optional-dependencies","text":"CryoGrid-pyTools has several optional dependency groups that can be installed based on your needs:","title":"Optional Dependencies"},{"location":"installation/#documentation-dependencies","text":"To build the documentation locally, install with the docs extra: pip install \"cryogrid_pytools[docs]\"","title":"Documentation Dependencies"},{"location":"installation/#data-processing-dependencies","text":"For additional data processing capabilities, install with the data extra: pip install \"cryogrid_pytools[data]\"","title":"Data Processing Dependencies"},{"location":"installation/#development-installation","text":"If you want to contribute to the development of CryoGrid-pyTools, you can install from source: git clone https://github.com/lukegre/CryoGrid-pyTools.git cd CryoGrid-pyTools pip install -e \".[docs,data]\" # install with all optional dependencies","title":"Development Installation"},{"location":"installation/#requirements","text":"CryoGrid-pyTools requires Python 3.9 or later. The main dependencies are: numpy >= 2.0 scipy >= 1.13.1 xarray >= 2024 pandas >= 2 dask[array,diagnostics] >= 2024 These dependencies will be automatically installed when you install the package using pip.","title":"Requirements"},{"location":"usage/getting-started/","text":"Getting Started This guide will help you get started with CryoGrid-pyTools. The package provides various functions to work with CryoGrid data in Python. Basic Usage First, import the package: import cryogrid_pytools as cgt The package provides several main functionalities: Reading CryoGrid output files Processing MATLAB struct files Working with ERA5 forcing data Handling configuration files Check out the specific guides for each functionality: Reading CryoGrid Output Reading MATLAB Structs Example Notebook For comprehensive examples, check out the demo.ipynb notebook in the repository. It contains detailed examples of various use cases and functionalities.","title":"Getting Started"},{"location":"usage/getting-started/#getting-started","text":"This guide will help you get started with CryoGrid-pyTools. The package provides various functions to work with CryoGrid data in Python.","title":"Getting Started"},{"location":"usage/getting-started/#basic-usage","text":"First, import the package: import cryogrid_pytools as cgt The package provides several main functionalities: Reading CryoGrid output files Processing MATLAB struct files Working with ERA5 forcing data Handling configuration files Check out the specific guides for each functionality: Reading CryoGrid Output Reading MATLAB Structs","title":"Basic Usage"},{"location":"usage/getting-started/#example-notebook","text":"For comprehensive examples, check out the demo.ipynb notebook in the repository. It contains detailed examples of various use cases and functionalities.","title":"Example Notebook"},{"location":"usage/reading-matlab/","text":"Reading MATLAB Structs CryoGrid-pyTools provides functionality to read MATLAB struct files into Python. Here's how to work with MATLAB data. Important Note Warning The run_info.mat file cannot be read directly as it contains special classes not supported by scipy.io.loadmat . You'll need to save the required data in a different format from MATLAB. Preparing MATLAB Data When working in MATLAB, ensure you: Add the CryoGrid/source directory to the MATLAB path before saving files Save data in a compatible format For example, to save parts of run_info , use this MATLAB code: % Save specific variables from run_info save('my_data.mat', 'variable1', 'variable2', '-v7.3') Reading MATLAB Files in Python Once you have your MATLAB data in a compatible format: import cryogrid_pytools as cgt # Read the MATLAB file data = cgt.read_matlab_file('my_data.mat') The data will be converted to appropriate Python data structures, making it easy to work with in your Python environment.","title":"Reading MATLAB Structs"},{"location":"usage/reading-matlab/#reading-matlab-structs","text":"CryoGrid-pyTools provides functionality to read MATLAB struct files into Python. Here's how to work with MATLAB data.","title":"Reading MATLAB Structs"},{"location":"usage/reading-matlab/#important-note","text":"Warning The run_info.mat file cannot be read directly as it contains special classes not supported by scipy.io.loadmat . You'll need to save the required data in a different format from MATLAB.","title":"Important Note"},{"location":"usage/reading-matlab/#preparing-matlab-data","text":"When working in MATLAB, ensure you: Add the CryoGrid/source directory to the MATLAB path before saving files Save data in a compatible format For example, to save parts of run_info , use this MATLAB code: % Save specific variables from run_info save('my_data.mat', 'variable1', 'variable2', '-v7.3')","title":"Preparing MATLAB Data"},{"location":"usage/reading-matlab/#reading-matlab-files-in-python","text":"Once you have your MATLAB data in a compatible format: import cryogrid_pytools as cgt # Read the MATLAB file data = cgt.read_matlab_file('my_data.mat') The data will be converted to appropriate Python data structures, making it easy to work with in your Python environment.","title":"Reading MATLAB Files in Python"},{"location":"usage/reading-output/","text":"Reading CryoGrid Output CryoGrid-pyTools currently supports reading output files from the OUT_regridded_FCI2 class. Here's how to work with these files. Reading Single Files To read a single CryoGrid output file: import cryogrid_pytools as cgt # Path to your output file fname = \"results_from_RUN_SIMPLE/<project_name>_<YYYYMMDD>.mat\" # Read the file dataset = cgt.read_OUT_regridded_FCI2_file(fname) Reading Multiple Files For projects using RUN_SPATIAL_SPINUP_CLUSTERING, you can read multiple files at once: # Path with wildcards for cluster ID and date fname = \"results_from_RUN_SPATIAL_SPINUP_CLUSTERING/project_name_*_*.mat\" # Read multiple files, specifying the deepest point dataset = cgt.read_OUT_regridded_FCI2_clusters(fname, deepest_point=-5) The resulting dataset is an xarray.Dataset with dimensions: - gridcell - depth - time This makes it easy to perform analysis and visualization using xarray's powerful features.","title":"Reading CryoGrid Output"},{"location":"usage/reading-output/#reading-cryogrid-output","text":"CryoGrid-pyTools currently supports reading output files from the OUT_regridded_FCI2 class. Here's how to work with these files.","title":"Reading CryoGrid Output"},{"location":"usage/reading-output/#reading-single-files","text":"To read a single CryoGrid output file: import cryogrid_pytools as cgt # Path to your output file fname = \"results_from_RUN_SIMPLE/<project_name>_<YYYYMMDD>.mat\" # Read the file dataset = cgt.read_OUT_regridded_FCI2_file(fname)","title":"Reading Single Files"},{"location":"usage/reading-output/#reading-multiple-files","text":"For projects using RUN_SPATIAL_SPINUP_CLUSTERING, you can read multiple files at once: # Path with wildcards for cluster ID and date fname = \"results_from_RUN_SPATIAL_SPINUP_CLUSTERING/project_name_*_*.mat\" # Read multiple files, specifying the deepest point dataset = cgt.read_OUT_regridded_FCI2_clusters(fname, deepest_point=-5) The resulting dataset is an xarray.Dataset with dimensions: - gridcell - depth - time This makes it easy to perform analysis and visualization using xarray's powerful features.","title":"Reading Multiple Files"},{"location":"usage/spatial-data/","text":"Spatial Data and Forcing The data module provides tools for creating forcing data and spatial data for CryoGrid spatial cluster runs. This module requires additional dependencies which can be installed using: pip install \"cryogrid_pytools[data]\" Digital Elevation Model (DEM) You can download DEM data from the Copernicus 30m dataset: import cryogrid_pytools as cgt # Define your area of interest (West, South, East, North) bbox = [70.0, 35.0, 71.0, 36.0] # Example for a region in the Pamirs # Get DEM data at 30m resolution dem = cgt.data.get_dem_copernicus30( bbox_WSEN=bbox, res_m=30, epsg=32643, # UTM 43N (default for Pamir region) smoothing_iters=2, # Apply smoothing to reduce noise smoothing_size=3 # Kernel size for smoothing ) Land Cover Data Get ESA World Cover data for your region: landcover = cgt.data.get_esa_land_cover( bbox_WSEN=bbox, res_m=30, epsg=32643 ) The returned DataArray includes attributes for class values, descriptions, and colors that can be used for plotting. Snow Melt Timing Calculate snow melt timing using Sentinel-2 data: # Get snow melt day of year for multiple years snow_melt = cgt.data.get_snow_melt_doy( bbox_WSEN=bbox, years=range(2018, 2025), # Analysis period res_m=30, epsg=32643 ) Glacier Data Get Randolph Glacier Inventory (RGI) data for your region: # Get glacier data as a raster matching your DEM glacier_data = cgt.data.get_randolph_glacier_inventory(target_dem=dem) # Or get raw vector data glacier_vector = cgt.data.get_randolph_glacier_inventory() ERA5 Forcing Data The module provides access to ERA5 climate forcing data through the era5_downloader package: from cryogrid_pytools.data import make_era5_downloader # Create an ERA5 downloader instance era5 = make_era5_downloader() # Download ERA5 data for your region and time period forcing = era5.get_data( bbox_WSEN=bbox, start_date=\"2018-01-01\", end_date=\"2024-12-31\" ) Advanced Usage Smoothing Data You can smooth any spatial data using a rolling mean filter: smoothed_dem = cgt.data.smooth_data( dem, kernel_size=3, n_iters=2 ) Working with Sentinel-2 Data Get raw Sentinel-2 data for custom analysis: sentinel_data = cgt.data.get_sentinel2_data( bbox_WSEN=bbox, years=range(2018, 2025), assets=['SCL'], # Scene Classification Layer res_m=30, epsg=32643, max_cloud_cover=5 # Maximum cloud cover percentage ) Notes All spatial functions support consistent coordinate reference systems through the epsg parameter Resolution can be specified in meters using the res_m parameter The module handles data downloads and caching automatically Most functions support both vector (GeoDataFrame) and raster (xarray.DataArray) outputs Functions are decorated to handle both bounding box inputs and existing DataArrays for reprojection","title":"Spatial Data and Forcing"},{"location":"usage/spatial-data/#spatial-data-and-forcing","text":"The data module provides tools for creating forcing data and spatial data for CryoGrid spatial cluster runs. This module requires additional dependencies which can be installed using: pip install \"cryogrid_pytools[data]\"","title":"Spatial Data and Forcing"},{"location":"usage/spatial-data/#digital-elevation-model-dem","text":"You can download DEM data from the Copernicus 30m dataset: import cryogrid_pytools as cgt # Define your area of interest (West, South, East, North) bbox = [70.0, 35.0, 71.0, 36.0] # Example for a region in the Pamirs # Get DEM data at 30m resolution dem = cgt.data.get_dem_copernicus30( bbox_WSEN=bbox, res_m=30, epsg=32643, # UTM 43N (default for Pamir region) smoothing_iters=2, # Apply smoothing to reduce noise smoothing_size=3 # Kernel size for smoothing )","title":"Digital Elevation Model (DEM)"},{"location":"usage/spatial-data/#land-cover-data","text":"Get ESA World Cover data for your region: landcover = cgt.data.get_esa_land_cover( bbox_WSEN=bbox, res_m=30, epsg=32643 ) The returned DataArray includes attributes for class values, descriptions, and colors that can be used for plotting.","title":"Land Cover Data"},{"location":"usage/spatial-data/#snow-melt-timing","text":"Calculate snow melt timing using Sentinel-2 data: # Get snow melt day of year for multiple years snow_melt = cgt.data.get_snow_melt_doy( bbox_WSEN=bbox, years=range(2018, 2025), # Analysis period res_m=30, epsg=32643 )","title":"Snow Melt Timing"},{"location":"usage/spatial-data/#glacier-data","text":"Get Randolph Glacier Inventory (RGI) data for your region: # Get glacier data as a raster matching your DEM glacier_data = cgt.data.get_randolph_glacier_inventory(target_dem=dem) # Or get raw vector data glacier_vector = cgt.data.get_randolph_glacier_inventory()","title":"Glacier Data"},{"location":"usage/spatial-data/#era5-forcing-data","text":"The module provides access to ERA5 climate forcing data through the era5_downloader package: from cryogrid_pytools.data import make_era5_downloader # Create an ERA5 downloader instance era5 = make_era5_downloader() # Download ERA5 data for your region and time period forcing = era5.get_data( bbox_WSEN=bbox, start_date=\"2018-01-01\", end_date=\"2024-12-31\" )","title":"ERA5 Forcing Data"},{"location":"usage/spatial-data/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"usage/spatial-data/#smoothing-data","text":"You can smooth any spatial data using a rolling mean filter: smoothed_dem = cgt.data.smooth_data( dem, kernel_size=3, n_iters=2 )","title":"Smoothing Data"},{"location":"usage/spatial-data/#working-with-sentinel-2-data","text":"Get raw Sentinel-2 data for custom analysis: sentinel_data = cgt.data.get_sentinel2_data( bbox_WSEN=bbox, years=range(2018, 2025), assets=['SCL'], # Scene Classification Layer res_m=30, epsg=32643, max_cloud_cover=5 # Maximum cloud cover percentage )","title":"Working with Sentinel-2 Data"},{"location":"usage/spatial-data/#notes","text":"All spatial functions support consistent coordinate reference systems through the epsg parameter Resolution can be specified in meters using the res_m parameter The module handles data downloads and caching automatically Most functions support both vector (GeoDataFrame) and raster (xarray.DataArray) outputs Functions are decorated to handle both bounding box inputs and existing DataArrays for reprojection","title":"Notes"}]}